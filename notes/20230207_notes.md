# SCRIPT OG Metagenomics Data

# 20230207

concatenated reads from Batch_04A1 and Batch_04A2

Starting analysis with updated processing

Making sample sheet
    python3 workflow/scripts/prep_sample_sheet.py --delimiter="_S" --path="/scratch/jsj3921/Batch_01" --subdirectories=True
    python3 workflow/scripts/prep_sample_sheet.py --delimiter="_S" --path="/scratch/jsj3921/Batch_02" --subdirectories=True --out="./config/sample_sheet_02.tsv"
    python3 workflow/scripts/prep_sample_sheet.py --delimiter="_S" --path="/scratch/jsj3921/Batch_03" --subdirectories=True --out="./config/sample_sheet_03.tsv"
    python3 workflow/scripts/prep_sample_sheet.py --delimiter="_R" --r1_common="R1" --r2_common="R2" --path="/scratch/jsj3921/Batch_04A12" --subdirectories=True --out="./config/sample_sheet_04.tsv"
    python3 workflow/scripts/prep_sample_sheet.py --delimiter="_R" --r1_common="R1" --r2_common="R2" --path="/scratch/jsj3921/Batch_04B" --subdirectories=True --out="./config/sample_sheet_04b.tsv"

Added 202221-Communal-Zymo to end of sample sheet as bioinformatic control

snakemake worked great

the following are 100% unknown from metaphlan 
     [1] "DNA_B03_21"  "DNA_B04_101" "DNA_B04_106" "DNA_B04_139" "DNA_B04_141" "DNA_B04_151" "DNA_B04_48"  "DNA_B04_61"  "DNA_B04_95"  "DNA_B04_98" 


# 20230109

Working on getting humann started
    Installing metaphlan 4 database required excessive RAM so had to do it in a batch job
    
    mamba activate /projects/b1180/software/conda_envs/humann/

    metaphlan 20221221-Comunal-Zymo.fastp_bowtie.r1.fastq.gz,20221221-Comunal-Zymo.fastp_bowtie.r2.fastq.gz --nproc 23 --input_type fastq -o mpatest.tsvls

Recent results from kraken2 and metaphlan output suggests a really interesting correlational relationship between groups of taxa 
This could be that there are taxa that have low competition with each other and thus co-associate and strong competition with others
that leads them to be co-exclusive
Some other taxa are just ok with being there independent of the other cohorts. Id hypothesize that these taxa provide some metabolic 
niche necessary for others and/or have different ecological constraints compared to the cohorts. That is, they can metabolize some 
rare but lung-abundant nutrient source. 
    Would be interesting if functional abundance profiles mimic the above, then find specific predictive metabolites

testing merging on humann/metaphlan output

module load BBMap
Usage for paired files:         bbmerge.sh in1=<read1> in2=<read2> out=<merged reads> outu1=<unmerged1> outu2=<unmerged2>
bbmerge.sh in1=20221221-Comunal-Zymo.fastp_bowtie.r1.fastq.gz in2=20221221-Comunal-Zymo.fastp_bowtie.r2.fastq.gz out=merged_test.fastq.gz outu1=unmergedout.1.fastq.gz outu2=unmergedout.2.fastq.gz

bbmerge.sh in1=20221221-Comunal-Zymo.fastp_bowtie.r1.fastq.gz \
    in2=20221221-Comunal-Zymo.fastp_bowtie.r2.fastq.gz \
    out=merged_test.fastq.gz \
    outu1=unmergedout.1.fastq.gz \
    outu2=unmergedout.2.fastq.gz \
    verystrict=t \
    k=60 \
    ihist=ihist.txt \
    mininsert=90
(will automatically make fast.gz)
- very strict = good for assembly based approached/reduced FP 
- k=60 is the kmer length used for overlap analysis/graph. Default is 31 but 60 is good for 150 PE
- mininsert=90 means that the min merged read length will be 90, which is noted in the literature as an optimal minimum for functional profiling

humann --input merged_test.fastq.gz --output humann_merged --threads 40 --memory-use maximum



bbmerge.sh in1=DNA_B04_115.fastp_bowtie.r1.fastq.gz \
    in2=DNA_B04_115.fastp_bowtie.r2.fastq.gz \
    out=merged_test.fastq.gz \
    outu1=unmergedout.1.fastq.gz \
    outu2=unmergedout.2.fastq.gz \
    verystrict=t \
    k=60 \
    ihist=ihist.txt \
    mininsert=90


# 20230210

Trying to add additional functionality to readQC module 

# 20230213

updated fastqc module to actually work

spades doesnt work with merged reads, so have to use PE reads

might try with megahit and use PE that dont merge in addition

with additional fastp parameters, complexity filter, etc additions to the pipeline, the n50
    decreased in spades outputs overall

# 20230214

Exploring freshly basecalled batch 4 samples to double check that nothign got corrupted along teh way

noticed that there is a wide distribution of reads in the samples, ranging from .fastq.gz files of size ~10M to ~1G

This may be the greater explanatory factor in why some samples just dont assemble well. 
    Must write code to visualize fastqc (and quast) multiqc outputs in order to contextualize/justify elimination

BCL Files in:
/scratch/jsj3921/bcl_files/SCRIPT_DNA_B04_PoolA_BCL_Files/RawFastq
/scratch/jsj3921/bcl_files/SCRIPT_DNA_B04_PoolA_Resequenced_BCL_Files/RawFastq
/scratch/jsj3921/bcl_files/SCRIPT_DNA_B04_PoolB_BCL_Files/RawFastq/RawFastq

PoolA1 starts with SCRIPT_DNA... so well keep that for now in order to differentiate between the sample types

Getting sample sheet ready
        python3 workflow/scripts/prep_sample_sheet.py --delimiter="_S" --path="/scratch/jsj3921/bcl_files/SCRIPT_DNA_B04_PoolA_BCL_Files/RawFastq"
        python3 workflow/scripts/prep_sample_sheet.py --delimiter="_S" --path="/scratch/jsj3921/bcl_files/SCRIPT_DNA_B04_PoolA_Resequenced_BCL_Files/RawFastq"
        python3 workflow/scripts/prep_sample_sheet.py --delimiter="_S" --path="/scratch/jsj3921/bcl_files/SCRIPT_DNA_B04_PoolB_BCL_Files/RawFastq/"