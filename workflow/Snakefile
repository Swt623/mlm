# The main entry point of your workflow.
# After configuring, running snakemake -n in a clone of this repository should successfully execute a dry-run of the workflow.
import itertools
import os 
import glob
import sys
import pandas as pd

configfile: "../config/config.yaml"
include: "rules/common.smk"
include: "rules/metagenomics.smk"
localrules: multiqc_trimmed

rule all:
    input:
        expand("../results/filtered/{dataset}/{sample}.filtered.R1.fastq.gz",
            zip, sample=samples["sample"], dataset=samples["dataset"]), #  FastP R2
        expand("../results/filtered/{dataset}/{sample}.filtered.R2.fastq.gz", 
            zip, sample=samples["sample"], dataset=samples["dataset"]), #  FastP R2
        expand("../results/filtered/{dataset}/fastqc/{sample}.filtered.R1_fastqc.html",
            zip, sample=samples["sample"], dataset=samples["dataset"]), #  FastQC
        expand("../results/bwa/{dataset}/{sample}.mapped.bam",
            zip, sample=samples["sample"], dataset=samples["dataset"]), #  BWA
        expand("../results/bwa/{dataset}/{sample}.unmapped.bam",
            zip, sample=samples["sample"], dataset=samples["dataset"]),  # BWA Unmapped
        expand("../results/bwa/{dataset}/{sample}.clean.R1.fastq",
            zip, sample=samples["sample"], dataset=samples["dataset"]), #  BWA fastq R1
        expand("../results/bwa/{dataset}/{sample}.clean.R2.fastq",
            zip, sample=samples["sample"], dataset=samples["dataset"]), #  BWA fastq R2
        directory("../resources/metaphlan_db"), #  Metaphlan setup/Database
        expand("../results/{dataset}/abundance/metaphlan/{sample}.metaphlan_profile.txt",
            zip, sample=samples["sample"], dataset=samples["dataset"]) # Metaphlan profiles

       # "../results/allDatasets/metaphlan/merged_abundance_table.allDatasets.txt" #  Metaphlan merged abundance table
    